{
  "hash": "ed7ca780095848bb236e0eb3fef067cd",
  "result": {
    "markdown": "---\ntitle: \"Deep Learning with Keras :: Cheatsheet\"\ndescription: \" \"\nimage-alt: \"\"\nexecute:\n  eval: false\n  output: true\n  warning: false\n---\n\n::: {.cell .column-margin}\n<img src=\"images/logo-tensorflow.png\" height=\"138\" alt=\"Hex logo for tensorflow - A red hexagon with a stylized 'TFR' (denoting TensorFlow for R) in a lighter shade of red, with the 'F' joined to the 'R'.\" />\n<br><br><a href=\"../keras.pdf\">\n<p><i class=\"bi bi-file-pdf\"></i> Download PDF</p>\n<img src=\"../pngs/keras.png\" width=\"200\" alt=\"\"/>\n</a>\n<br><br><p>Translations (PDF)</p>\n* <a href=\"../translations/chinese/keras_zh_cn.pdf\"><i class=\"bi bi-file-pdf\"></i>Chinese</a>\n* <a href=\"../translations/japanese/keras_ja.pdf\"><i class=\"bi bi-file-pdf\"></i>Japanese</a>\n* <a href=\"../translations/spanish/keras_es.pdf\"><i class=\"bi bi-file-pdf\"></i>Spanish</a>\n:::\n\n\n## Intro\n\n**Keras** is a high-level neural networks API developed with a focus on enabling fast experimentation.\nIt supports multiple back-ends, including TensorFlow, CNTK and Theano.\n\nTensorFlow is a lower level mathematical library for building deep neural network architectures.\nThe **keras** R package makes it easy to use Keras and TensorFlow in R.\n\n1.  **Define**: Model, Sequential model, Multi-GPU model\n2.  **Compile**: Optimizer, Loss, Metrics\n3.  **Fit**: Batch size, Epochs, Validation split\n4.  **Evaluate**: Evaluate, Plot\n5.  **Predict**: Classes, Probability\n\nRead more at:\\\n<https://tensorflow.rstudio.com>\\\n<https://www.manning.com/books/deep-learning-with-r-second-edition>\n\n### Installation\n\nThe keras R package uses the Python keras library.\nYou can install all the prerequisites directly from R: <https://tensorflow.rstudio.com/install>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\ninstall_keras()\n```\n:::\n\n\nSee `?install_keras` for GPU instructions.\n\nThis installs the required libraries in an Anaconda environment or virtual environment `r-tensorflow`.\n\n### Training an Image Recognizer on MNIST Data\n\nThe \"Hello, World!\" of deep learning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# input layer: use MNIST images\nmnist <- dataset_mnist()\nx_train <- mnist$train$x\ny_train <- mnist$train$y \nx_test <- mnist$test$x\ny_test <- mnist$test$y\n\n# reshape and rescale\nx_train <- array_reshape(x_train, c(nrow(x_train), 784)) \nx_test <- array_reshape(x_test, c(nrow(x_test), 784)) \nx_train <- x_train / 255\nx_test <- x_test / 255\n\ny_train <- to_categorical(y_train, 10) \ny_test <- to_categorical(y_test, 10)\n\n# defining the model and layers\nmodel <- keras_model_sequential() \nmodel %>%\n  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%\n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>% \n  layer_dense(units = 10, activation = 'softmax')\n  \n# compile (define loss and optimizer)\nmodel %>%\n  compile(\n    loss = 'categorical_crossentropy', \n    optimizer = optimizer_rmsprop(), \n    metrics = c('accuracy')\n)\n\n# train (fit)\nmodel %>% fit(\n  x_train, y_train,\n  epochs = 30, batch_size = 128, \n  validation_split = 0.2\n)\n\nmodel %>% evaluate(x_test, y_test) \nmodel %>% predict_classes(x_test)\n```\n:::\n\n\n## Working with keras models\n\n### Define a Model\n\n-   `keras_model()`: Keras Model.\n\n-   `keras_model_sequential()`: Keras Model composed of a linear stack of layers.\n\n-   `multi_gpu_model()`: Replicates a model on different GPUs.\n\n### Compile a Model\n\n-   `compile(object, optimizer, loss, metrics = NULL)`: Configure a Keras model for training.\n\n### Fit a Model\n\n-   `fit(object, x = NULL, y = NULL, batch_size = NULL, epochs = 10, verbose = 1, callbacks = NULL, ...)`: Train a Keras model for a fixed number of epochs (iterations).\n\n-   `fit_generator()`: Fits the model on data yielded batch-by-batch by a generator.\n\n-   `train_on_batch()`; `test_on_batch()`: Single gradient update or model evaluation over one batch of samples.\n\n### Evaluate a Model\n\n-   `evaluate(object, x = NULL, y = NULL, batch_size = NULL)`: Evaluate a Keras model.\n\n-   `evaluate_generator()`: Evaluates the model on a data generator.\n\n### Predict\n\n-   `predict()`: Generate predictions from a Keras model.\n\n-   `predict_proba()`; `predict_classes()`: Generates probability or class probability predictions for the input samples.\n\n-   `predict_on_batch()`: Returns predictions for a single batch of samples.\n\n-   `predict_generator()`: Generates predictions for the input samples from a data generator.\n\n### Other Model Operations\n\n-   `summary()`: Print a summary of a Keras model.\n\n-   `export_savedmodel()`: Export a saved model.\n\n-   `get_layer()`: Retrieves a layer based on either its name (unique) or index.\n\n-   `pop_layer()`: Remove the last layer in a model.\n\n-   `save_model_hdf5()`; `load_model_hdf5()`: Save/Load models using HDF5 files.\n\n-   `serialize_model()`; `unserialize_model()`: Serialize a model to an R object.\n\n-   `clone_model()`: Clone a model instance.\n\n-   `freeze_weights()`; `unfreeze_weights()`\n\n### Core Layers\n\n-   `layer_input()`: Input layer.\n\n-   `layer_dense()`: Add a densely-connected NN layer to an output.\n\n-   `layer_activation()`: Apply an activation function to an output.\n\n-   `layer_dropout()`: Applies Dropout to the input.\n\n-   `layer_reshape()`: Reshapes an output to a certain shape.\n\n-   `layer_permute()`: Permute the dimensions of an input according to a given pattern.\n\n-   `layer_repeat_vector()`: Repeats the input n times.\n\n-   `layer_lambda(object, f)`: Wraps arbitrary expression as a layer.\n\n-   `layer_activity_regularization()`: Layer that applies an update to the cost function based input activity.\n\n-   `layer_masking()`: Masks a sequence by using a mask value to skip timesteps.\n\n-   `layer_flatten()`: Flattens an input.\n\n<!-- Page 2 -->\n\n## More layers\n\n### Convolutional Layers\n\n-   `layer_conv_1d()`: 1D, e.g. temporal convolution.\n\n-   `layer_conv_2d_transpose()`: Transposed 2D (deconvolution).\n\n-   `layer_conv_2d()` : 2D, e.g. spatial convolution over images.\n\n-   `layer_conv_3d_transpose()`: Transposed 3D (deconvolution).\n\n-   `layer_conv_3d()`: 3D, e.g. spatial convolution over volumes.\n\n-   `layer_conv_lstm_2d()`: Convolutional LSTM.\n\n-   `layer_separable_conv_2d()`: Depthwise separable 2D.\n\n-   `layer_upsampling_1d()`; `layer_upsampling_2d()`; `layer_upsampling_3d()`: Upsampling layer.\n\n-   `layer_zero_padding_1d()`; `layer_zero_padding_2d()`; `layer_zero_padding_3d()`: Zero-padding layer.\n\n-   `layer_cropping_1d()`; `layer_cropping_2d()`; `layer_cropping_3d()`: Cropping layer.\n\n### Pooling Layers\n\n-   `layer_max_pooling_1d()`; `layer_max_pooling_2d()`; `layer_max_pooling_3d()`: Maximum pooling for 1D to 3D.\n\n-   `layer_average_pooling_1d()`; `layer_average_pooling_2d()`; `layer_average_pooling_3d()`: Average pooling for 1D to 3D.\n\n-   `layer_global_max_pooling_1d()`; `layer_global_max_pooling_2d()`; `layer_global_max_pooling_3d()`: Global maximum pooling.\n\n-   `layer_global_average_pooling_1d()`; `layer_global_average_pooling_2d()`; `layer_global_average_pooling_3d()`: Global average pooling.\n\n### Activation Layers\n\n-   `layer_activation(object, activation)`: Apply an activation function to an output.\n\n-   `layer_activation_leaky_relu()`: Leaky version of a rectified linear unit.\n\n-   `layer_activation_parametric_relu()`: Parametric rectified linear unit.\n\n-   `layer_activation_thresholded_relu()`: Thresholded rectified linear unit.\n\n-   `layer_activation_elu()`: Exponential linear unit.\n\n### Dropout Layers\n\n-   `layer_dropout()`: Applies dropout to the input.\n\n-   `layer_spatial_dropout_1d()`; `layer_spatial_dropout_2d()`; `layer_spatial_dropout_3d()`: Spatial 1D to 3D version of dropout\n\n### Recurrent Layers\n\n-   `layer_simple_rnn()`: Fully-connected RNN where the output is to be fed back to input.\n\n-   `layer_gru()`: Gated recurrent unit - Cho et al.\n\n-   `layer_cudnn_gru()`: Fast GRU implementation backed by CuDNN.\n\n-   `layer_lstm()`: Long-Short Term Memory unit - Hochreiter 1997.\n\n-   `layer_cudnn_lstm()`: Fast LSTM implementation backed by CuDNN.\n\n### Locally Connected Layers\n\n-   `layer_locally_connected_1d()`; `layer_locally_connected_2d()`: Similar to convolution, but weights are not shared, i.e. different filters for each patch.\n\n## Preprocessing\n\n### Sequence Preprocessing\n\n-   `pad_sequences()`: Pads each sequence to the same length (length of the longest sequence).\n\n-   `skipgrams()`: Generates skipgram word pairs.\n\n-   `make_sampling_table()`: Generates word rank-based probabilistic sampling table.\n\n### Text Preprocessing\n\n-   `text_tokenizer()`: Text tokenization utility.\n\n-   `fit_text_tokenizer()`: Update tokenizer internal vocabulary.\n\n-   `save_text_tokenizer()`; `load_text_tokenizer()`: Save a text tokenizer to an external file.\n\n-   `texts_to_sequences()`; `texts_to_sequences_generator()`: Transforms each text in texts to sequence of integers.\n\n-   `texts_to_matrix()`; `sequences_to_matrix()`: Convert a list of sequences into a matrix.\n\n-   `text_one_hot()`: One-hot encode text to word indices.\n\n-   `text_hashing_trick()`: Converts a text to a sequence of indexes in a fixed-size hashing space.\n\n-   `text_to_word_sequence()`: Convert text to a sequence of words (or tokens).\n\n### Image Proprocessing\n\n-   `image_load()`: Loads an image into PIL format.\n\n-   `flow_images_from_data()`; `flow_images_from_directory()`: Generates batches of augmented/normalized data from images and labels, or a directory.\n\n-   `image_data_generator()`: Generate minibatches of image data with real-time data augmentation.\n\n-   `fit_image_data_generator()`: Fit image data generator internal statistics to some sample data.\n\n-   `generator_next()`: Retrieve the next item.\n\n-   `image_to_array()`; `image_array_resize()`; `image_array_save()`: 3D array representation.\n\n## Pre-trained models\n\nKeras applications are deep learning models that are made available alongside pre-trained weights.\nThese models can be used for prediction, feature extraction, and fine-tuning.\n\n-   `application_xception()`; `xception_preprocess_input()`: Xception v1 model.\n\n-   `application_inception_v3()`; `inception_v3_preprocess_input()`: Inception v3 model, with weights pre-trained on ImageNet.\n\n-   `application_inception_resnet_v2()`; `inception_resnet_v2_preprocess_input()`: Inception-ResNet v2 model, with weights trained on ImageNet.\n\n-   `application_vgg16()`; `application_vgg19()`: VGG16 and VGG19 models.\n\n-   `application_resnet50()`: ResNet50 model.\n\n-   `application_mobilenet()`; `mobilenet_preprocess_input()`; `mobilenet_decode_predictions()`; `mobilenet_load_model_hdf5()`: MobileNet model architecture.\n\nImageNet is a large database of images with labels, extensively used for deep learning.\n\n-   `imagenet_preprocess_input()`; `imagenet_decode_predictions()`: Preprocesses a tensor encoding a batch of images for ImageNet, and decodes predictions.\n\n## Callbacks\n\nA callback is a set of functions to be applied at given stages of the training procedure.\nYou can use callbacks to get a view on internal states and statistics of the model during training.\n\n-   `allback_early_stopping()`: Stop training when a monitored quantity has stopped improving.\n\n-   `callback_learning_rate_scheduler()`: Learning rate scheduler.\n\n-   `callback_tensorboard()`: TensorBoard basic visualizations.\n\n------------------------------------------------------------------------\n\nCC BY SA Posit Software, PBC • [info\\@posit.co](mailto:info@posit.co) • [posit.co](https://posit.co)\n\nLearn more at [tensorflow.rstudio.com](https://tensorflow.rstudio.com/).\n\nUpdated: 2023-06.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackageVersion(\"keras\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] '2.11.1'\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}